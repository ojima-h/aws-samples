<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

  <!-- Hive Configuration can either be stored in this file or in the hadoop configuration files  -->
  <!-- that are implied by Hadoop setup variables.                                                -->
  <!-- Aside from Hadoop setup variables - this file is provided as a convenience so that Hive    -->
  <!-- users do not have to edit hadoop configuration files (that may be managed as a centralized -->
  <!-- resource).                                                                                 -->

  <!-- Hive Execution Parameters -->
  <property>
    <name>mapred.reduce.tasks</name>
    <value>-1</value>
    <description>The default number of reduce tasks per job. Typically set
      to a prime close to the number of available hosts. Ignored when
      mapred.job.tracker is "local". Hadoop set this to 1 by default, whereas hive uses -1 as its default value.
      By setting this property to -1, Hive will automatically figure out what should be the number of reducers.
    </description>
  </property>

  <property>
    <name>mapred.max.split.size</name>
    <value>256000000</value>
    <description>The maximum size chunk that map input should be split into.</description>
  </property>

  <property>
    <name>hive.exec.scratchdir</name>
    <value>/tmp/hive-${user.name}</value>
    <description>Scratch space for Hive jobs</description>
  </property>

  <property>
      <name>hive.exec.local.scratchdir</name>
      <value>/mnt/var/lib/hive/tmp/local-${user.name}</value>
      <description>Local scratch space for Hive jobs</description>
  </property>


  <property>
    <name>hive.exec.skips3scratch</name>
    <value>true</value>
    <description>Do not write temp files to S3 scratch space. This will increase the performance by avoiding multiple
      writes in S3, but can corrupt the table or partition being written to, esp. if the job fails.
    </description>
  </property>

  <property>
    <name>hive.querylog.location</name>
    <value>/mnt/var/lib/hive/tmp/history-${user.name}</value>
    <description>Location of command line history</description>
  </property>

  <property>
    <name>hive.server2.logging.operation.log.location</name>
    <value>/mnt/var/lib/hive/tmp/operation-${user.name}</value>
    <description>Top level directory where operation logs are stored if logging functionality is enabled</description>
  </property>

  <property>
    <name>hive.downloaded.resources.dir</name>
    <value>/mnt/var/lib/hive/downloaded_resources</value>
    <description>Place to put resources downloaded from S3</description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true</value>
    <description>JDBC connect string for a JDBC metastore</description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.jdbc.Driver</value>
    <description>Driver class name for a JDBC metastore</description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hive</value>
    <description>username to use against metastore database</description>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>hive</value>
    <description>password to use against metastore database</description>
  </property>

  <!--<property>-->
    <!--<name>datanucleus.cache.level2.type</name>-->
    <!--<value>SOFT</value>-->
    <!--<description>SOFT=soft reference based cache, WEAK=weak reference based cache.</description>-->
  <!--</property>-->

  <property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/user/hive/warehouse</value>
    <description>location of default database for the warehouse</description>
  </property>

  <property>
    <name>hive.metastore.connect.retries</name>
    <value>5</value>
    <description>Number of retries while opening a connection to metastore</description>
  </property>

  <!--<property>-->
    <!--<name>hive.mapper.cannot.span.multiple.partitions</name>-->
    <!--<value>true</value>-->
  <!--</property>-->

  <property>
    <name>datanucleus.fixedDatastore</name>
    <value>true</value>
  </property>

  <property><name>hive.server2.authentication</name><value>NOSASL</value></property>
</configuration>
